{"ast":null,"code":"'use strict';\n\nvar util = require('util');\n\nvar _ = require('lodash');\n\nvar Readable = require('stream').Readable;\n\nvar logger = require('./logging')('kafka-node:ConsumerStream');\n\nconst Denque = require('denque');\n\nvar CommitStream = require('./commitStream');\n\nvar protocol = require('./protocol');\n\nvar DEFAULTS = {\n  groupId: 'kafka-node-group',\n  // Auto commit config\n  autoCommit: true,\n  autoCommitMsgCount: 100,\n  autoCommitIntervalMs: 5000,\n  // Fetch message config\n  fetchMaxWaitMs: 100,\n  fetchMinBytes: 1,\n  fetchMaxBytes: 1024 * 1024,\n  bufferRefetchThreshold: 10,\n  fromOffset: false,\n  encoding: 'utf8'\n};\n\nvar ConsumerStream = function (client, topics, options) {\n  options.objectMode = true;\n  this.highWaterMark = options.highWaterMark = options.highWaterMark || 100;\n  Readable.call(this, options);\n\n  if (_.isEmpty(topics)) {\n    throw new Error('You must specify topics to subscribe to.');\n  } // Whether we have sent a fetch request for which we have not yet received\n  // all messages.\n\n\n  this.fetchInFlight = false;\n  this.fetchCount = 0;\n  this.client = client;\n  this.options = _.defaults(options || {}, DEFAULTS);\n  this.ready = false;\n  this.payloads = this.buildPayloads(topics);\n  this.connect();\n  this.encoding = this.options.encoding;\n  this.emittedMessages = 0;\n  this.messageBuffer = new Denque();\n  this._reading = false;\n  this.close = this.close.bind(this);\n};\n\nutil.inherits(ConsumerStream, Readable); // The older non-stream based consumer emitted `message` events rather\n// than data events. This provides a backward compatibility layer for\n// receiving message events instead.\n\nConsumerStream.prototype._emit = ConsumerStream.prototype.emit;\n\nConsumerStream.prototype.emit = function () {\n  if (arguments[0] === 'data') {\n    this._emit('message', arguments[1]);\n  }\n\n  this._emit.apply(this, arguments);\n};\n/**\n * Implements the abstract Readable::_read() method.\n */\n\n\nConsumerStream.prototype._read = function () {\n  this._reading = true;\n  this.transmitMessages();\n};\n/**\n * Buffers the received message then checks to see if we should send.\n *\n * Messages are fetched from Kafka with a size limit and not a message\n * count while node.js object streams have a limit in object count. As\n * a result we maintain an internal buffer (this.messageBuffer) from\n * which we push messages onto the stream as appropriate in\n * this.transmitMessages().\n *\n * @param {Object} message - An Kafka message object.\n */\n\n\nConsumerStream.prototype.handleMessage = function (message) {\n  this.messageBuffer.push(message);\n  this.transmitMessages();\n};\n\nConsumerStream.prototype.transmitMessages = function () {\n  while (this._reading && !this.messageBuffer.isEmpty()) {\n    this._reading = this.push(this.messageBuffer.shift());\n  }\n\n  if (this.messageBuffer.isEmpty() && this._reading) {\n    this.fetch();\n  }\n};\n/**\n * Fetch messages from kafka if appropriate.\n */\n\n\nConsumerStream.prototype.fetch = function () {\n  var self = this;\n\n  if (self.ready && !self.fetchInFlight) {\n    self.fetchInFlight = true;\n    var encoder = protocol.encodeFetchRequest(self.fetchMaxWaitMs, self.fetchMinBytes);\n    var decoder = protocol.decodeFetchResponse(self.decodeCallback.bind(self), self.maxTickMessages);\n    self.client.send(self.payloads, encoder, decoder, function (err) {\n      if (err) {\n        Array.prototype.unshift.call(arguments, 'error');\n        self.emit.apply(self, arguments);\n      } // If the buffer is below the configured threshold attempt a fetch.\n\n\n      if (self.messageBuffer.length < self.options.bufferRefetchThreshold) {\n        setImmediate(function () {\n          self.fetch();\n        });\n      }\n    });\n  }\n};\n/**\n * The decode callback is invoked as data is decoded from the response.\n */\n\n\nConsumerStream.prototype.decodeCallback = function (err, type, message) {\n  if (err) {\n    switch (err.message) {\n      case 'OffsetOutOfRange':\n        return this.emit('offsetOutOfRange', err);\n\n      case 'NotLeaderForPartition':\n        return this.emit('brokersChanged');\n\n      default:\n        return this.emit('error', err);\n    }\n  }\n\n  var encoding = this.options.encoding;\n\n  if (type === 'message') {\n    if (encoding !== 'buffer' && message.value) {\n      message.value = message.value.toString(encoding);\n    }\n\n    this.handleMessage(message);\n  } else if (type === 'done') {\n    // If we had neither error nor message, this is the end of a fetch,\n    // and we should update the offset for the next fetch.\n    this.updateOffsets(message);\n    this.fetchInFlight = false;\n  }\n};\n\nConsumerStream.prototype.connect = function () {\n  var self = this; // Client already exists\n\n  if (this.client.ready) {\n    this.init();\n  }\n\n  this.client.on('ready', function () {\n    logger.debug('consumer ready');\n    if (!self.ready) self.init();\n  });\n  this.client.on('error', function (err) {\n    logger.debug('client error %s', err.message);\n    self.emit('error', err);\n  });\n  this.client.on('close', function () {\n    logger.debug('connection closed');\n  });\n  this.client.on('brokersChanged', function () {\n    var topicNames = self.payloads.map(function (p) {\n      return p.topic;\n    });\n    this.refreshMetadata(topicNames, function (err) {\n      if (err) return self.emit('error', err);\n    });\n  });\n};\n\nConsumerStream.prototype.updateOffsets = function (topics, initing) {\n  this.payloads.forEach(function (p) {\n    if (!_.isEmpty(topics[p.topic]) && topics[p.topic][p.partition] !== undefined) {\n      var offset = topics[p.topic][p.partition]; // Note, we track the offset of the next message we want to see,\n      // not the most recent message we have seen.\n\n      if (offset === -1) offset = 0;\n      if (!initing) p.offset = offset + 1;else p.offset = offset;\n    }\n  });\n};\n\nConsumerStream.prototype.close = function (force, cb) {\n  if (typeof force === 'function') {\n    cb = force;\n    force = false;\n  }\n\n  let self = this;\n\n  if (force) {\n    self.commit(function (err) {\n      self.emit('error', err);\n      self.client.close(cb);\n    });\n  } else {\n    self.client.close(cb);\n  }\n\n  this.ready = false;\n};\n\nConsumerStream.prototype.init = function () {\n  if (!this.payloads.length) {\n    return;\n  }\n\n  var self = this;\n  var topics = self.payloads.map(function (p) {\n    return p.topic;\n  });\n  self.client.topicExists(topics, function (err) {\n    if (err) {\n      return self.emit('error', err);\n    }\n\n    var start = function () {\n      self.emit('readable');\n      self.ready = true; // If this consumer was piped immediately then read may have been called\n      // before readable was emitted so we should trigger a fetch.\n\n      if (self._reading) {\n        setImmediate(function () {\n          self.fetch();\n        });\n      }\n    };\n\n    if (self.options.fromOffset) {\n      return start();\n    }\n\n    self.client.sendOffsetFetchRequest(self.options.groupId, self.payloads, function (err, topics) {\n      if (err) {\n        return self.emit('error', err);\n      }\n\n      self.updateOffsets(topics, true);\n      start();\n    });\n  });\n};\n\nConsumerStream.prototype.buildPayloads = function (payloads) {\n  var self = this;\n  return payloads.map(function (p) {\n    if (typeof p !== 'object') p = {\n      topic: p\n    };\n    p.partition = p.partition || 0;\n    p.offset = p.offset || 0;\n    p.maxBytes = self.options.fetchMaxBytes;\n    p.metadata = 'm'; // metadata can be arbitrary\n\n    return p;\n  });\n};\n\nConsumerStream.prototype.createCommitStream = function (options) {\n  options = options || this.options;\n  options = _.defaults(options || {}, this.options);\n  return new CommitStream(this.client, this.payloads, this.options.groupId, options);\n};\n\nmodule.exports = ConsumerStream;","map":{"version":3,"sources":["/home/jerem/Bureau/Cours/IWA/stopcovid-front/node_modules/kafka-node/lib/consumerStream.js"],"names":["util","require","_","Readable","logger","Denque","CommitStream","protocol","DEFAULTS","groupId","autoCommit","autoCommitMsgCount","autoCommitIntervalMs","fetchMaxWaitMs","fetchMinBytes","fetchMaxBytes","bufferRefetchThreshold","fromOffset","encoding","ConsumerStream","client","topics","options","objectMode","highWaterMark","call","isEmpty","Error","fetchInFlight","fetchCount","defaults","ready","payloads","buildPayloads","connect","emittedMessages","messageBuffer","_reading","close","bind","inherits","prototype","_emit","emit","arguments","apply","_read","transmitMessages","handleMessage","message","push","shift","fetch","self","encoder","encodeFetchRequest","decoder","decodeFetchResponse","decodeCallback","maxTickMessages","send","err","Array","unshift","length","setImmediate","type","value","toString","updateOffsets","init","on","debug","topicNames","map","p","topic","refreshMetadata","initing","forEach","partition","undefined","offset","force","cb","commit","topicExists","start","sendOffsetFetchRequest","maxBytes","metadata","createCommitStream","module","exports"],"mappings":"AAAA;;AACA,IAAIA,IAAI,GAAGC,OAAO,CAAC,MAAD,CAAlB;;AACA,IAAIC,CAAC,GAAGD,OAAO,CAAC,QAAD,CAAf;;AACA,IAAIE,QAAQ,GAAGF,OAAO,CAAC,QAAD,CAAP,CAAkBE,QAAjC;;AACA,IAAIC,MAAM,GAAGH,OAAO,CAAC,WAAD,CAAP,CAAqB,2BAArB,CAAb;;AACA,MAAMI,MAAM,GAAGJ,OAAO,CAAC,QAAD,CAAtB;;AACA,IAAIK,YAAY,GAAGL,OAAO,CAAC,gBAAD,CAA1B;;AAEA,IAAIM,QAAQ,GAAGN,OAAO,CAAC,YAAD,CAAtB;;AAEA,IAAIO,QAAQ,GAAG;AACbC,EAAAA,OAAO,EAAE,kBADI;AAEb;AACAC,EAAAA,UAAU,EAAE,IAHC;AAIbC,EAAAA,kBAAkB,EAAE,GAJP;AAKbC,EAAAA,oBAAoB,EAAE,IALT;AAMb;AACAC,EAAAA,cAAc,EAAE,GAPH;AAQbC,EAAAA,aAAa,EAAE,CARF;AASbC,EAAAA,aAAa,EAAE,OAAO,IATT;AAUbC,EAAAA,sBAAsB,EAAE,EAVX;AAWbC,EAAAA,UAAU,EAAE,KAXC;AAYbC,EAAAA,QAAQ,EAAE;AAZG,CAAf;;AAeA,IAAIC,cAAc,GAAG,UAAUC,MAAV,EAAkBC,MAAlB,EAA0BC,OAA1B,EAAmC;AACtDA,EAAAA,OAAO,CAACC,UAAR,GAAqB,IAArB;AACA,OAAKC,aAAL,GAAqBF,OAAO,CAACE,aAAR,GAAwBF,OAAO,CAACE,aAAR,IAAyB,GAAtE;AACArB,EAAAA,QAAQ,CAACsB,IAAT,CAAc,IAAd,EAAoBH,OAApB;;AACA,MAAIpB,CAAC,CAACwB,OAAF,CAAUL,MAAV,CAAJ,EAAuB;AACrB,UAAM,IAAIM,KAAJ,CAAU,0CAAV,CAAN;AACD,GANqD,CAOtD;AACA;;;AACA,OAAKC,aAAL,GAAqB,KAArB;AACA,OAAKC,UAAL,GAAkB,CAAlB;AACA,OAAKT,MAAL,GAAcA,MAAd;AACA,OAAKE,OAAL,GAAepB,CAAC,CAAC4B,QAAF,CAAWR,OAAO,IAAI,EAAtB,EAA0Bd,QAA1B,CAAf;AACA,OAAKuB,KAAL,GAAa,KAAb;AACA,OAAKC,QAAL,GAAgB,KAAKC,aAAL,CAAmBZ,MAAnB,CAAhB;AACA,OAAKa,OAAL;AACA,OAAKhB,QAAL,GAAgB,KAAKI,OAAL,CAAaJ,QAA7B;AACA,OAAKiB,eAAL,GAAuB,CAAvB;AACA,OAAKC,aAAL,GAAqB,IAAI/B,MAAJ,EAArB;AACA,OAAKgC,QAAL,GAAgB,KAAhB;AACA,OAAKC,KAAL,GAAa,KAAKA,KAAL,CAAWC,IAAX,CAAgB,IAAhB,CAAb;AACD,CArBD;;AAsBAvC,IAAI,CAACwC,QAAL,CAAcrB,cAAd,EAA8BhB,QAA9B,E,CAEA;AACA;AACA;;AACAgB,cAAc,CAACsB,SAAf,CAAyBC,KAAzB,GAAiCvB,cAAc,CAACsB,SAAf,CAAyBE,IAA1D;;AACAxB,cAAc,CAACsB,SAAf,CAAyBE,IAAzB,GAAgC,YAAY;AAC1C,MAAIC,SAAS,CAAC,CAAD,CAAT,KAAiB,MAArB,EAA6B;AAC3B,SAAKF,KAAL,CAAW,SAAX,EAAsBE,SAAS,CAAC,CAAD,CAA/B;AACD;;AACD,OAAKF,KAAL,CAAWG,KAAX,CAAiB,IAAjB,EAAuBD,SAAvB;AACD,CALD;AAOA;AACA;AACA;;;AACAzB,cAAc,CAACsB,SAAf,CAAyBK,KAAzB,GAAiC,YAAY;AAC3C,OAAKT,QAAL,GAAgB,IAAhB;AACA,OAAKU,gBAAL;AACD,CAHD;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA5B,cAAc,CAACsB,SAAf,CAAyBO,aAAzB,GAAyC,UAAUC,OAAV,EAAmB;AAC1D,OAAKb,aAAL,CAAmBc,IAAnB,CAAwBD,OAAxB;AACA,OAAKF,gBAAL;AACD,CAHD;;AAKA5B,cAAc,CAACsB,SAAf,CAAyBM,gBAAzB,GAA4C,YAAY;AACtD,SAAO,KAAKV,QAAL,IAAiB,CAAC,KAAKD,aAAL,CAAmBV,OAAnB,EAAzB,EAAuD;AACrD,SAAKW,QAAL,GAAgB,KAAKa,IAAL,CAAU,KAAKd,aAAL,CAAmBe,KAAnB,EAAV,CAAhB;AACD;;AACD,MAAI,KAAKf,aAAL,CAAmBV,OAAnB,MAAgC,KAAKW,QAAzC,EAAmD;AACjD,SAAKe,KAAL;AACD;AACF,CAPD;AASA;AACA;AACA;;;AACAjC,cAAc,CAACsB,SAAf,CAAyBW,KAAzB,GAAiC,YAAY;AAC3C,MAAIC,IAAI,GAAG,IAAX;;AACA,MAAIA,IAAI,CAACtB,KAAL,IAAc,CAACsB,IAAI,CAACzB,aAAxB,EAAuC;AACrCyB,IAAAA,IAAI,CAACzB,aAAL,GAAqB,IAArB;AACA,QAAI0B,OAAO,GAAG/C,QAAQ,CAACgD,kBAAT,CAA4BF,IAAI,CAACxC,cAAjC,EAAiDwC,IAAI,CAACvC,aAAtD,CAAd;AACA,QAAI0C,OAAO,GAAGjD,QAAQ,CAACkD,mBAAT,CAA6BJ,IAAI,CAACK,cAAL,CAAoBnB,IAApB,CAAyBc,IAAzB,CAA7B,EAA6DA,IAAI,CAACM,eAAlE,CAAd;AACAN,IAAAA,IAAI,CAACjC,MAAL,CAAYwC,IAAZ,CAAiBP,IAAI,CAACrB,QAAtB,EAAgCsB,OAAhC,EAAyCE,OAAzC,EAAkD,UAAUK,GAAV,EAAe;AAC/D,UAAIA,GAAJ,EAAS;AACPC,QAAAA,KAAK,CAACrB,SAAN,CAAgBsB,OAAhB,CAAwBtC,IAAxB,CAA6BmB,SAA7B,EAAwC,OAAxC;AACAS,QAAAA,IAAI,CAACV,IAAL,CAAUE,KAAV,CAAgBQ,IAAhB,EAAsBT,SAAtB;AACD,OAJ8D,CAK/D;;;AACA,UAAIS,IAAI,CAACjB,aAAL,CAAmB4B,MAAnB,GAA4BX,IAAI,CAAC/B,OAAL,CAAaN,sBAA7C,EAAqE;AACnEiD,QAAAA,YAAY,CAAC,YAAY;AACvBZ,UAAAA,IAAI,CAACD,KAAL;AACD,SAFW,CAAZ;AAGD;AACF,KAXD;AAYD;AACF,CAnBD;AAqBA;AACA;AACA;;;AACAjC,cAAc,CAACsB,SAAf,CAAyBiB,cAAzB,GAA0C,UAAUG,GAAV,EAAeK,IAAf,EAAqBjB,OAArB,EAA8B;AACtE,MAAIY,GAAJ,EAAS;AACP,YAAQA,GAAG,CAACZ,OAAZ;AACE,WAAK,kBAAL;AACE,eAAO,KAAKN,IAAL,CAAU,kBAAV,EAA8BkB,GAA9B,CAAP;;AACF,WAAK,uBAAL;AACE,eAAO,KAAKlB,IAAL,CAAU,gBAAV,CAAP;;AACF;AACE,eAAO,KAAKA,IAAL,CAAU,OAAV,EAAmBkB,GAAnB,CAAP;AANJ;AAQD;;AAED,MAAI3C,QAAQ,GAAG,KAAKI,OAAL,CAAaJ,QAA5B;;AAEA,MAAIgD,IAAI,KAAK,SAAb,EAAwB;AACtB,QAAIhD,QAAQ,KAAK,QAAb,IAAyB+B,OAAO,CAACkB,KAArC,EAA4C;AAC1ClB,MAAAA,OAAO,CAACkB,KAAR,GAAgBlB,OAAO,CAACkB,KAAR,CAAcC,QAAd,CAAuBlD,QAAvB,CAAhB;AACD;;AACD,SAAK8B,aAAL,CAAmBC,OAAnB;AACD,GALD,MAKO,IAAIiB,IAAI,KAAK,MAAb,EAAqB;AAC1B;AACA;AACA,SAAKG,aAAL,CAAmBpB,OAAnB;AACA,SAAKrB,aAAL,GAAqB,KAArB;AACD;AACF,CAzBD;;AA2BAT,cAAc,CAACsB,SAAf,CAAyBP,OAAzB,GAAmC,YAAY;AAC7C,MAAImB,IAAI,GAAG,IAAX,CAD6C,CAG7C;;AACA,MAAI,KAAKjC,MAAL,CAAYW,KAAhB,EAAuB;AACrB,SAAKuC,IAAL;AACD;;AAED,OAAKlD,MAAL,CAAYmD,EAAZ,CAAe,OAAf,EAAwB,YAAY;AAClCnE,IAAAA,MAAM,CAACoE,KAAP,CAAa,gBAAb;AACA,QAAI,CAACnB,IAAI,CAACtB,KAAV,EAAiBsB,IAAI,CAACiB,IAAL;AAClB,GAHD;AAKA,OAAKlD,MAAL,CAAYmD,EAAZ,CAAe,OAAf,EAAwB,UAAUV,GAAV,EAAe;AACrCzD,IAAAA,MAAM,CAACoE,KAAP,CAAa,iBAAb,EAAgCX,GAAG,CAACZ,OAApC;AACAI,IAAAA,IAAI,CAACV,IAAL,CAAU,OAAV,EAAmBkB,GAAnB;AACD,GAHD;AAKA,OAAKzC,MAAL,CAAYmD,EAAZ,CAAe,OAAf,EAAwB,YAAY;AAClCnE,IAAAA,MAAM,CAACoE,KAAP,CAAa,mBAAb;AACD,GAFD;AAIA,OAAKpD,MAAL,CAAYmD,EAAZ,CAAe,gBAAf,EAAiC,YAAY;AAC3C,QAAIE,UAAU,GAAGpB,IAAI,CAACrB,QAAL,CAAc0C,GAAd,CAAkB,UAAUC,CAAV,EAAa;AAC9C,aAAOA,CAAC,CAACC,KAAT;AACD,KAFgB,CAAjB;AAIA,SAAKC,eAAL,CAAqBJ,UAArB,EAAiC,UAAUZ,GAAV,EAAe;AAC9C,UAAIA,GAAJ,EAAS,OAAOR,IAAI,CAACV,IAAL,CAAU,OAAV,EAAmBkB,GAAnB,CAAP;AACV,KAFD;AAGD,GARD;AASD,CA/BD;;AAiCA1C,cAAc,CAACsB,SAAf,CAAyB4B,aAAzB,GAAyC,UAAUhD,MAAV,EAAkByD,OAAlB,EAA2B;AAClE,OAAK9C,QAAL,CAAc+C,OAAd,CAAsB,UAAUJ,CAAV,EAAa;AACjC,QAAI,CAACzE,CAAC,CAACwB,OAAF,CAAUL,MAAM,CAACsD,CAAC,CAACC,KAAH,CAAhB,CAAD,IAA+BvD,MAAM,CAACsD,CAAC,CAACC,KAAH,CAAN,CAAgBD,CAAC,CAACK,SAAlB,MAAiCC,SAApE,EAA+E;AAC7E,UAAIC,MAAM,GAAG7D,MAAM,CAACsD,CAAC,CAACC,KAAH,CAAN,CAAgBD,CAAC,CAACK,SAAlB,CAAb,CAD6E,CAE7E;AACA;;AACA,UAAIE,MAAM,KAAK,CAAC,CAAhB,EAAmBA,MAAM,GAAG,CAAT;AACnB,UAAI,CAACJ,OAAL,EAAcH,CAAC,CAACO,MAAF,GAAWA,MAAM,GAAG,CAApB,CAAd,KACKP,CAAC,CAACO,MAAF,GAAWA,MAAX;AACN;AACF,GATD;AAUD,CAXD;;AAaA/D,cAAc,CAACsB,SAAf,CAAyBH,KAAzB,GAAiC,UAAU6C,KAAV,EAAiBC,EAAjB,EAAqB;AACpD,MAAI,OAAOD,KAAP,KAAiB,UAArB,EAAiC;AAC/BC,IAAAA,EAAE,GAAGD,KAAL;AACAA,IAAAA,KAAK,GAAG,KAAR;AACD;;AACD,MAAI9B,IAAI,GAAG,IAAX;;AAEA,MAAI8B,KAAJ,EAAW;AACT9B,IAAAA,IAAI,CAACgC,MAAL,CAAY,UAAUxB,GAAV,EAAe;AACzBR,MAAAA,IAAI,CAACV,IAAL,CAAU,OAAV,EAAmBkB,GAAnB;AACAR,MAAAA,IAAI,CAACjC,MAAL,CAAYkB,KAAZ,CAAkB8C,EAAlB;AACD,KAHD;AAID,GALD,MAKO;AACL/B,IAAAA,IAAI,CAACjC,MAAL,CAAYkB,KAAZ,CAAkB8C,EAAlB;AACD;;AACD,OAAKrD,KAAL,GAAa,KAAb;AACD,CAhBD;;AAkBAZ,cAAc,CAACsB,SAAf,CAAyB6B,IAAzB,GAAgC,YAAY;AAC1C,MAAI,CAAC,KAAKtC,QAAL,CAAcgC,MAAnB,EAA2B;AACzB;AACD;;AAED,MAAIX,IAAI,GAAG,IAAX;AACA,MAAIhC,MAAM,GAAGgC,IAAI,CAACrB,QAAL,CAAc0C,GAAd,CAAkB,UAAUC,CAAV,EAAa;AAC1C,WAAOA,CAAC,CAACC,KAAT;AACD,GAFY,CAAb;AAIAvB,EAAAA,IAAI,CAACjC,MAAL,CAAYkE,WAAZ,CAAwBjE,MAAxB,EAAgC,UAAUwC,GAAV,EAAe;AAC7C,QAAIA,GAAJ,EAAS;AACP,aAAOR,IAAI,CAACV,IAAL,CAAU,OAAV,EAAmBkB,GAAnB,CAAP;AACD;;AAED,QAAI0B,KAAK,GAAG,YAAY;AACtBlC,MAAAA,IAAI,CAACV,IAAL,CAAU,UAAV;AACAU,MAAAA,IAAI,CAACtB,KAAL,GAAa,IAAb,CAFsB,CAItB;AACA;;AACA,UAAIsB,IAAI,CAAChB,QAAT,EAAmB;AACjB4B,QAAAA,YAAY,CAAC,YAAY;AACvBZ,UAAAA,IAAI,CAACD,KAAL;AACD,SAFW,CAAZ;AAGD;AACF,KAXD;;AAaA,QAAIC,IAAI,CAAC/B,OAAL,CAAaL,UAAjB,EAA6B;AAC3B,aAAOsE,KAAK,EAAZ;AACD;;AAEDlC,IAAAA,IAAI,CAACjC,MAAL,CAAYoE,sBAAZ,CAAmCnC,IAAI,CAAC/B,OAAL,CAAab,OAAhD,EAAyD4C,IAAI,CAACrB,QAA9D,EAAwE,UAAU6B,GAAV,EAAexC,MAAf,EAAuB;AAC7F,UAAIwC,GAAJ,EAAS;AACP,eAAOR,IAAI,CAACV,IAAL,CAAU,OAAV,EAAmBkB,GAAnB,CAAP;AACD;;AAEDR,MAAAA,IAAI,CAACgB,aAAL,CAAmBhD,MAAnB,EAA2B,IAA3B;AACAkE,MAAAA,KAAK;AACN,KAPD;AAQD,GA9BD;AA+BD,CAzCD;;AA2CApE,cAAc,CAACsB,SAAf,CAAyBR,aAAzB,GAAyC,UAAUD,QAAV,EAAoB;AAC3D,MAAIqB,IAAI,GAAG,IAAX;AACA,SAAOrB,QAAQ,CAAC0C,GAAT,CAAa,UAAUC,CAAV,EAAa;AAC/B,QAAI,OAAOA,CAAP,KAAa,QAAjB,EAA2BA,CAAC,GAAG;AAAEC,MAAAA,KAAK,EAAED;AAAT,KAAJ;AAC3BA,IAAAA,CAAC,CAACK,SAAF,GAAcL,CAAC,CAACK,SAAF,IAAe,CAA7B;AACAL,IAAAA,CAAC,CAACO,MAAF,GAAWP,CAAC,CAACO,MAAF,IAAY,CAAvB;AACAP,IAAAA,CAAC,CAACc,QAAF,GAAapC,IAAI,CAAC/B,OAAL,CAAaP,aAA1B;AACA4D,IAAAA,CAAC,CAACe,QAAF,GAAa,GAAb,CAL+B,CAKb;;AAClB,WAAOf,CAAP;AACD,GAPM,CAAP;AAQD,CAVD;;AAYAxD,cAAc,CAACsB,SAAf,CAAyBkD,kBAAzB,GAA8C,UAAUrE,OAAV,EAAmB;AAC/DA,EAAAA,OAAO,GAAGA,OAAO,IAAI,KAAKA,OAA1B;AACAA,EAAAA,OAAO,GAAGpB,CAAC,CAAC4B,QAAF,CAAWR,OAAO,IAAI,EAAtB,EAA0B,KAAKA,OAA/B,CAAV;AACA,SAAO,IAAIhB,YAAJ,CAAiB,KAAKc,MAAtB,EAA8B,KAAKY,QAAnC,EAA6C,KAAKV,OAAL,CAAab,OAA1D,EAAmEa,OAAnE,CAAP;AACD,CAJD;;AAMAsE,MAAM,CAACC,OAAP,GAAiB1E,cAAjB","sourcesContent":["'use strict';\nvar util = require('util');\nvar _ = require('lodash');\nvar Readable = require('stream').Readable;\nvar logger = require('./logging')('kafka-node:ConsumerStream');\nconst Denque = require('denque');\nvar CommitStream = require('./commitStream');\n\nvar protocol = require('./protocol');\n\nvar DEFAULTS = {\n  groupId: 'kafka-node-group',\n  // Auto commit config\n  autoCommit: true,\n  autoCommitMsgCount: 100,\n  autoCommitIntervalMs: 5000,\n  // Fetch message config\n  fetchMaxWaitMs: 100,\n  fetchMinBytes: 1,\n  fetchMaxBytes: 1024 * 1024,\n  bufferRefetchThreshold: 10,\n  fromOffset: false,\n  encoding: 'utf8'\n};\n\nvar ConsumerStream = function (client, topics, options) {\n  options.objectMode = true;\n  this.highWaterMark = options.highWaterMark = options.highWaterMark || 100;\n  Readable.call(this, options);\n  if (_.isEmpty(topics)) {\n    throw new Error('You must specify topics to subscribe to.');\n  }\n  // Whether we have sent a fetch request for which we have not yet received\n  // all messages.\n  this.fetchInFlight = false;\n  this.fetchCount = 0;\n  this.client = client;\n  this.options = _.defaults(options || {}, DEFAULTS);\n  this.ready = false;\n  this.payloads = this.buildPayloads(topics);\n  this.connect();\n  this.encoding = this.options.encoding;\n  this.emittedMessages = 0;\n  this.messageBuffer = new Denque();\n  this._reading = false;\n  this.close = this.close.bind(this);\n};\nutil.inherits(ConsumerStream, Readable);\n\n// The older non-stream based consumer emitted `message` events rather\n// than data events. This provides a backward compatibility layer for\n// receiving message events instead.\nConsumerStream.prototype._emit = ConsumerStream.prototype.emit;\nConsumerStream.prototype.emit = function () {\n  if (arguments[0] === 'data') {\n    this._emit('message', arguments[1]);\n  }\n  this._emit.apply(this, arguments);\n};\n\n/**\n * Implements the abstract Readable::_read() method.\n */\nConsumerStream.prototype._read = function () {\n  this._reading = true;\n  this.transmitMessages();\n};\n\n/**\n * Buffers the received message then checks to see if we should send.\n *\n * Messages are fetched from Kafka with a size limit and not a message\n * count while node.js object streams have a limit in object count. As\n * a result we maintain an internal buffer (this.messageBuffer) from\n * which we push messages onto the stream as appropriate in\n * this.transmitMessages().\n *\n * @param {Object} message - An Kafka message object.\n */\nConsumerStream.prototype.handleMessage = function (message) {\n  this.messageBuffer.push(message);\n  this.transmitMessages();\n};\n\nConsumerStream.prototype.transmitMessages = function () {\n  while (this._reading && !this.messageBuffer.isEmpty()) {\n    this._reading = this.push(this.messageBuffer.shift());\n  }\n  if (this.messageBuffer.isEmpty() && this._reading) {\n    this.fetch();\n  }\n};\n\n/**\n * Fetch messages from kafka if appropriate.\n */\nConsumerStream.prototype.fetch = function () {\n  var self = this;\n  if (self.ready && !self.fetchInFlight) {\n    self.fetchInFlight = true;\n    var encoder = protocol.encodeFetchRequest(self.fetchMaxWaitMs, self.fetchMinBytes);\n    var decoder = protocol.decodeFetchResponse(self.decodeCallback.bind(self), self.maxTickMessages);\n    self.client.send(self.payloads, encoder, decoder, function (err) {\n      if (err) {\n        Array.prototype.unshift.call(arguments, 'error');\n        self.emit.apply(self, arguments);\n      }\n      // If the buffer is below the configured threshold attempt a fetch.\n      if (self.messageBuffer.length < self.options.bufferRefetchThreshold) {\n        setImmediate(function () {\n          self.fetch();\n        });\n      }\n    });\n  }\n};\n\n/**\n * The decode callback is invoked as data is decoded from the response.\n */\nConsumerStream.prototype.decodeCallback = function (err, type, message) {\n  if (err) {\n    switch (err.message) {\n      case 'OffsetOutOfRange':\n        return this.emit('offsetOutOfRange', err);\n      case 'NotLeaderForPartition':\n        return this.emit('brokersChanged');\n      default:\n        return this.emit('error', err);\n    }\n  }\n\n  var encoding = this.options.encoding;\n\n  if (type === 'message') {\n    if (encoding !== 'buffer' && message.value) {\n      message.value = message.value.toString(encoding);\n    }\n    this.handleMessage(message);\n  } else if (type === 'done') {\n    // If we had neither error nor message, this is the end of a fetch,\n    // and we should update the offset for the next fetch.\n    this.updateOffsets(message);\n    this.fetchInFlight = false;\n  }\n};\n\nConsumerStream.prototype.connect = function () {\n  var self = this;\n\n  // Client already exists\n  if (this.client.ready) {\n    this.init();\n  }\n\n  this.client.on('ready', function () {\n    logger.debug('consumer ready');\n    if (!self.ready) self.init();\n  });\n\n  this.client.on('error', function (err) {\n    logger.debug('client error %s', err.message);\n    self.emit('error', err);\n  });\n\n  this.client.on('close', function () {\n    logger.debug('connection closed');\n  });\n\n  this.client.on('brokersChanged', function () {\n    var topicNames = self.payloads.map(function (p) {\n      return p.topic;\n    });\n\n    this.refreshMetadata(topicNames, function (err) {\n      if (err) return self.emit('error', err);\n    });\n  });\n};\n\nConsumerStream.prototype.updateOffsets = function (topics, initing) {\n  this.payloads.forEach(function (p) {\n    if (!_.isEmpty(topics[p.topic]) && topics[p.topic][p.partition] !== undefined) {\n      var offset = topics[p.topic][p.partition];\n      // Note, we track the offset of the next message we want to see,\n      // not the most recent message we have seen.\n      if (offset === -1) offset = 0;\n      if (!initing) p.offset = offset + 1;\n      else p.offset = offset;\n    }\n  });\n};\n\nConsumerStream.prototype.close = function (force, cb) {\n  if (typeof force === 'function') {\n    cb = force;\n    force = false;\n  }\n  let self = this;\n\n  if (force) {\n    self.commit(function (err) {\n      self.emit('error', err);\n      self.client.close(cb);\n    });\n  } else {\n    self.client.close(cb);\n  }\n  this.ready = false;\n};\n\nConsumerStream.prototype.init = function () {\n  if (!this.payloads.length) {\n    return;\n  }\n\n  var self = this;\n  var topics = self.payloads.map(function (p) {\n    return p.topic;\n  });\n\n  self.client.topicExists(topics, function (err) {\n    if (err) {\n      return self.emit('error', err);\n    }\n\n    var start = function () {\n      self.emit('readable');\n      self.ready = true;\n\n      // If this consumer was piped immediately then read may have been called\n      // before readable was emitted so we should trigger a fetch.\n      if (self._reading) {\n        setImmediate(function () {\n          self.fetch();\n        });\n      }\n    };\n\n    if (self.options.fromOffset) {\n      return start();\n    }\n\n    self.client.sendOffsetFetchRequest(self.options.groupId, self.payloads, function (err, topics) {\n      if (err) {\n        return self.emit('error', err);\n      }\n\n      self.updateOffsets(topics, true);\n      start();\n    });\n  });\n};\n\nConsumerStream.prototype.buildPayloads = function (payloads) {\n  var self = this;\n  return payloads.map(function (p) {\n    if (typeof p !== 'object') p = { topic: p };\n    p.partition = p.partition || 0;\n    p.offset = p.offset || 0;\n    p.maxBytes = self.options.fetchMaxBytes;\n    p.metadata = 'm'; // metadata can be arbitrary\n    return p;\n  });\n};\n\nConsumerStream.prototype.createCommitStream = function (options) {\n  options = options || this.options;\n  options = _.defaults(options || {}, this.options);\n  return new CommitStream(this.client, this.payloads, this.options.groupId, options);\n};\n\nmodule.exports = ConsumerStream;\n"]},"metadata":{},"sourceType":"script"}